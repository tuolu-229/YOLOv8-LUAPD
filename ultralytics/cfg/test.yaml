# Ultralytics YOLO ğŸš€, AGPL-3.0 license
# Default training settings and hyperparameters for medium-augmentation COCO training

task: detect  # (str) YOLO task, i.e. detect, segment, classify, pose
mode: train  # (str) YOLO mode, i.e. train, val, predict, export, track, benchmark

# Train settings -------------------------------------------------------------------------------------------------------
model:  # (str, optional) path to model file, i.e. yolov8n.pt, yolov8n.yaml
data: D:\software\pycharm_project\original_ultralytics-main\driver\data.yaml  # (str, optional) path to data file, i.e. coco128.yaml
epochs: 1  # (int) number of epochs to train for
patience: 2  # ç­‰å¾…æ²¡æœ‰æ˜æ˜¾æ”¹å–„ä»¥æå‰åœæ­¢è®­ç»ƒçš„æ—¶æœŸ  (int) epochs to wait for no observable improvement for early stopping of training
batch: 8  # æ¯æ‰¹å›¾åƒæ•°ï¼ˆè‡ªåŠ¨æ‰¹å¤„ç†ä¸º -1ï¼‰ (int) number of images per batch (-1 for AutoBatch)
imgsz: 640  # (int | list) input images size as int for train and val modes, or list[w,h] for predict and export modes
save: True  # ä¿å­˜åˆ—è½¦æ£€æŸ¥ç‚¹å¹¶é¢„æµ‹ç»“æœ (bool) save train checkpoints and predict results
save_period: -1 #ä¿å­˜åˆ—è½¦æ£€æŸ¥ç‚¹å¹¶é¢„æµ‹ç»“æœ (int) Save checkpoint every x epochs (disabled if < 1)
cache: disk  #111 çœŸ/å†…å­˜ã€ç£ç›˜æˆ–å‡ã€‚ä½¿ç”¨ç¼“å­˜åŠ è½½æ•°æ® Trueä¼šåŠ å¿«è¿è¡Œé€Ÿåº¦ï¼Œä½†æ˜¯åƒå†…å­˜ (bool) True/ram, disk or False. Use cache for data loading
device:  # è°ƒç”¨çš„æ—¶å“ªä¸ªgpu  (int | str | list, optional) device to run on, i.e. cuda device=0 or device=0,1,2,3 or device=cpu
workers: 8  #ç”¨äºæ•°æ®åŠ è½½çš„å·¥ä½œçº¿ç¨‹æ•°ï¼ˆå¦‚æœä¸º DDPï¼Œåˆ™æŒ‰ RANK è®¡ç®—ï¼‰ï¼ŒæœåŠ¡å™¨å¯è®¾ç½®ä¸º8  (int) number of worker threads for data loading (per RANK if DDP)
project:  # é¡¹ç›®åç§° (str, optional) project name
name:  #å®éªŒåç§°  (str, optional) experiment name, results saved to 'project/name' directory
exist_ok: False  # 	æ˜¯å¦è¦†ç›–ç°æœ‰å®éªŒ (bool) whether to overwrite existing experiment
optimizer: SGD  #111è¦ä½¿ç”¨çš„ä¼˜åŒ–å™¨ï¼Œ choices=[SGDï¼Œ Adamï¼Œ Adamaxï¼Œ AdamWï¼Œ NAdamï¼Œ RAdamï¼Œ RMSPropï¼Œ auto]        (str) optimizer to use, choices=[SGD, Adam, Adamax, AdamW, NAdam, RAdam, RMSProp, auto]
verbose: False  #111æ˜¯å¦æ‰“å°è¯¦ç»†è¾“å‡º     (bool) whether to print verbose output
seed: 0  #ç”¨äºé‡ç°æ€§çš„éšæœºç§å­  (int) random seed for reproducibility
deterministic: True  #æ˜¯å¦å¯ç”¨ç¡®å®šæ€§æ¨¡å¼ï¼Œä¿è¯å®éªŒçš„å¯å¤ç°æ€§ã€‚  (bool) whether to enable deterministic mode
single_cls: False  #å°†å¤šç±»æ•°æ®è®­ç»ƒä¸ºå•ç±»ï¼Œå¦‚æœä½ çš„æ•°æ®é›†æ˜¯å¤šç±»åˆ«ï¼Œè¿™ä¸ªå‚æ•°è®¾ç½®ä¸ºTrueçš„è¯ï¼Œå…¶ä¼šå½“åšä¸€ä¸ªç±»åˆ«æ¥è¿›è¡Œè®­ç»ƒï¼Œç›¸å½“äºåªè´Ÿè´£è¯†åˆ«ç›®æ ‡ï¼Œä¸è´Ÿè´£è¯†åˆ«ç±»åˆ«ã€‚  (bool) train multi-class data as single-class
rect: False  #å½¢è®­ç»ƒï¼Œæ¯æ‰¹æ•´ç†ä»¥è·å¾—æœ€å°çš„å¡«å……  (bool) rectangular training if mode='train' or rectangular validation if mode='val'
cos_lr: False  # ä½¿ç”¨ä½™å¼¦å­¦ä¹ é€Ÿç‡è°ƒåº¦ç¨‹åº  (bool) use cosine learning rate scheduler
close_mosaic: 10  #é»˜è®¤å€¼ä¸º10ï¼Œæ„æ€å°±æ˜¯åœ¨æœ€å10ä¸ªepochså…³é—­é©¬èµ›å…‹æ•°æ®å¢å¼º   (int) disable mosaic augmentation for final epochs
resume: True  #æ˜¯å¦ç»§ç»­ä¸Šä¸€æ¬¡æ²¡å®Œæˆçš„è®­ç»ƒ   (bool) resume training from last checkpoint
amp: True  # è‡ªåŠ¨æ··åˆç²¾åº¦ ï¼ˆAMPï¼‰ è®­ç»ƒï¼Œé€‰æ‹©=[çœŸï¼Œå‡]     (bool) Automatic Mixed Precision (AMP) training, choices=[True, False], True runs AMP check
fraction: 1.0  #	è¦è®­ç»ƒçš„æ•°æ®é›†åˆ†æ•°ï¼ˆé»˜è®¤å€¼ä¸º 1.0ï¼Œè®­ç»ƒé›†ä¸­çš„æ‰€æœ‰å›¾åƒï¼‰     (float) dataset fraction to train on (default is 1.0, all images in train set)
profile: False  #åœ¨è®°å½•å™¨è®­ç»ƒæœŸé—´åˆ†æ ONNX å’Œ TensorRT é€Ÿåº¦    (bool) profile ONNX and TensorRT speeds during training for loggers
# Segmentation
overlap_mask: True  # (bool) masks should overlap during training (segment train only)
mask_ratio: 4  # (int) mask downsample ratio (segment train only)
# Classification
dropout: False  #111è®­ç»ƒæœŸé—´å£ç½©åº”é‡å ï¼ˆä»…é™åˆ†æ®µè®­ç»ƒï¼‰ (float) use dropout regularization (classify train only)

# Val/Test settings ----------------------------------------------------------------------------------------------------
val: True  # (bool) validate/test during training
split: val  #æ•°æ®é›†æ‹†åˆ†ç”¨äºéªŒè¯ï¼Œå³â€œvalâ€ã€â€œtestâ€æˆ–â€œtrain,æ­¤å¤„æŒ‡valè¿™ä¸ªæ•°æ®é›†ç”¨äºéªŒè¯  (str) dataset split to use for validation, i.e. 'val', 'test' or 'train'
save_json: False  #å°†ç»“æœä¿å­˜åˆ° JSON æ–‡ä»¶ save results to JSON file
save_hybrid: False  # ä¿å­˜æ··åˆç‰ˆæœ¬çš„æ ‡ç­¾ï¼ˆæ ‡ç­¾ + å…¶ä»–é¢„æµ‹ï¼‰ save hybrid version of labels (labels + additional predictions)
conf:   #ç”¨äºæ£€æµ‹çš„å¯¹è±¡ç½®ä¿¡åº¦é˜ˆå€¼,é¢„æµ‹æ—¶é»˜è®¤0.25ï¼ŒéªŒè¯é»˜è®¤æ—¶0.001 object confidence threshold for detection (default 0.25 predict, 0.001 val)
iou: 0.7  #NMS çš„è”åˆ ï¼ˆIoUï¼‰ é˜ˆå€¼ä¸Šçš„äº¤é›†  (float) intersection over union (IoU) threshold for NMS
max_det: 300  #	æ¯ä¸ªå›¾åƒçš„æœ€å¤§æ£€æµ‹æ•°  (int) maximum number of detections per image
half: True  #111	ä½¿ç”¨åŠç²¾åº¦ ï¼ˆFP16ï¼‰ use half precision (FP16)
dnn: False  #ä½¿ç”¨ OpenCV DNN è¿›è¡Œ ONNX æ¨ç† (bool) use OpenCV DNN for ONNX inference
plots: True  #æ¯ä¸ªå›¾åƒçš„æœ€å¤§æ£€æµ‹æ•° (bool) save plots during train/val

# Prediction settings é¢„æµ‹æ¨¡å‹çš„å‚æ•°è®¾ç½®  conf iou imgsz half device save:ä¿å­˜åŒ…å«ç»“æœçš„å›¾åƒ-----------------------------------------------------------------
source:  # å›¾ç‰‡æˆ–è§†é¢‘çš„æºç›®å½•(str, optional) source directory for images or videos  å›¾åƒæ‰€åœ¨ä½ç½®
show: False  # 	å¦‚æœå¯èƒ½ï¼Œæ˜¾ç¤ºç»“æœ (bool) show results if possible  æ˜¯å¦æ˜¾ç¤ºç»“æœ
save_txt: False  # 	å°†ç»“æœå¦å­˜ä¸º.txtæ–‡ä»¶  (bool) save results as .txt file   å°†ç»“æœä¿å­˜æˆtxt
save_conf: False  #	ä½¿ç”¨ç½®ä¿¡åº¦åˆ†æ•°ä¿å­˜ç»“æœ  (bool) save results with confidence scores  ä¿å­˜å¾…ç½®ä¿¡åº¦å¾—åˆ†çš„ç»“æœ
save_crop: False  #	ä¿å­˜è£å‰ªçš„å›¾åƒå’Œç»“æœ (bool) save cropped images with results     ä¿å­˜è£å‰ªåå¸¦ç»“æœçš„å›¾åƒ
show_labels: True  # (bool) show object labels in plots         åœ¨ç»˜å›¾ä¸­æ˜¾ç¤ºå¯¹è±¡æ ‡ç­¾
show_conf: True  # (bool) show object confidence scores in plots  åœ¨ç»˜å›¾ä¸­æ˜¾ç¤ºç½®ä¿¡åº¦å¾—åˆ†
vid_stride: 1  # (int) video frame-rate stride                  è§†é¢‘å¸§ç‡è·¨åº¦
line_width:   # (int, optional) line width of the bounding boxes, auto if missing   è¾¹ç•Œæ¡†çš„åšåº¦ï¼ˆåƒç´ ï¼‰
visualize: False  # (bool) visualize model features             å¯è§†åŒ–æ¨¡å‹çš„ç‰¹å¾
augment: False  #æ˜¯å¦ä½¿ç”¨æµ‹è¯•æ•°æ®å¢å¼º  (bool) apply image augmentation to prediction sources   å¯¹æµ‹è¯•çœ¼åº”ç”¨å›¾åƒåŠ å¼º
agnostic_nms: False  # (bool) class-agnostic NMS                    ç±»æ— å…³NMS
classes:  # (int | list[int], optional) filter results by class, i.e. class=0, or class=[0,2,3]	æŒ‰ç±»è¿‡æ»¤ç»“æœï¼Œå³ç±»=0ï¼Œæˆ–ç±»=[0ï¼Œ2ï¼Œ3]
retina_masks: False  # (bool) use high-resolution segmentation masks      ä½¿ç”¨é«˜åˆ†è¾¨ç‡åˆ†å‰²æ©è†œ
boxes: True  # (bool) Show boxes in segmentation predictions      åœ¨åˆ†å‰²é¢„æµ‹ä¸­æ˜¾ç¤ºè¾¹ç•Œæ¡†

# Export settings ------------------------------------------------------------------------------------------------------
format: torchscript  # (str) format to export to, choices at https://docs.ultralytics.com/modes/export/#export-formats
keras: False  # (bool) use Kera=s
optimize: False  # (bool) TorchScript: optimize for mobile
int8: False  # (bool) CoreML/TF INT8 quantization
dynamic: False  # (bool) ONNX/TF/TensorRT: dynamic axes
simplify: False  # (bool) ONNX: simplify model
opset: 17  #111 (int, optional) ONNX: opset version
workspace: 4  # (int) TensorRT: workspace size (GB)
nms: False  # (bool) CoreML: add NMS

# Hyperparameters ------------------------------------------------------------------------------------------------------
lr0: 0.01  #åˆå§‹å­¦ä¹ ç‡    (float) initial learning rate (i.e. SGD=1E-2, Adam=1E-3)
lrf: 0.01  #æœ€ç»ˆå­¦ä¹ ç‡       (float) final learning rate (lr0 * lrf)
momentum: 0.937  #æ–°åŠ å¡å…ƒåŠ¨é‡/äºšå½“è´å¡”1     (float) SGD momentum/Adam beta1
weight_decay: 0.001  #111ä¼˜åŒ–å™¨é‡é‡è¡°å‡ 5E-4    (float) optimizer weight decay 5e-4
warmup_epochs: 3.0  #ä¼˜åŒ–å™¨é‡é‡è¡°å‡ 5E-4        (float) warmup epochs (fractions ok)
warmup_momentum: 0.8  #é¢„çƒ­åˆå§‹åŠ¨é‡    (float) warmup initial momentum
warmup_bias_lr: 0.1  #	é¢„çƒ­åˆå§‹åç½® LR     (float) warmup initial bias lr
box: 7.5  #	ç®±å­æŸå¤±æ”¶ç›Š    (float) box loss gain
cls: 0.5  #	CLS æŸè€—å¢ç›Šï¼ˆéšåƒç´ ç¼©æ”¾ï¼‰    (float) cls loss gain (scale with pixels)
dfl: 1.5  # 	CLS æŸè€—å¢ç›Šï¼ˆéšåƒç´ ç¼©æ”¾ï¼‰   (float) dfl loss gain
pose: 12.0  #	å§¿åŠ¿æŸå¤±å¢ç›Šï¼ˆä»…å§¿åŠ¿ï¼‰  (float) pose loss gain
kobj: 1.0  #	å…³é”®ç‚¹ OBJ æŸå¤±å¢ç›Šï¼ˆä»…å§¿åŠ¿ (float) keypoint obj loss gain
label_smoothing: 0.0  #æ ‡ç­¾å¹³æ»‘ï¼ˆåˆ†æ•°ï¼‰    (float) label smoothing (fraction)
nbs: 64  #å…¬ç§°æ‰¹é‡å¤§å° (int) nominal batch size
hsv_h: 0.015  # (float) image HSV-Hue augmentation (fraction)
hsv_s: 0.7  # (float) image HSV-Saturation augmentation (fraction)
hsv_v: 0.4  # (float) image HSV-Value augmentation (fraction)
degrees: 0.0  # (float) image rotation (+/- deg)
translate: 0.1  # (float) image translation (+/- fraction)
scale: 0.5  # (float) image scale (+/- gain)
shear: 0.0  # (float) image shear (+/- deg)
perspective: 0.0  # (float) image perspective (+/- fraction), range 0-0.001
flipud: 0.0  # (float) image flip up-down (probability)
fliplr: 0.5  # (float) image flip left-right (probability)
mosaic: 1.0  # (float) image mosaic (probability)
mixup: 0.0  # (float) image mixup (probability)
copy_paste: 0.0  # (float) segment copy-paste (probability)

# Custom config.yaml ---------------------------------------------------------------------------------------------------
cfg:  # (str, optional) for overriding defaults.yaml

# Tracker settings ------------------------------------------------------------------------------------------------------
tracker: botsort.yaml  # (str) tracker type, choices=[botsort.yaml, bytetrack.yaml]
